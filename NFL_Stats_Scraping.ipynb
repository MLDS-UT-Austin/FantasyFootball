{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MLDS-UT-Austin/FantasyFootball/blob/main/NFL_Stats_Scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PAXdQ-xzb3VO"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Lh0z5MI-cU0D"
   },
   "outputs": [],
   "source": [
    "base_url = \"https://www.pro-football-reference.com\"\n",
    "stat_categories = [\"passing\", \"scrimmage\", \"kicking\"]\n",
    "\n",
    "if not os.path.exists(\"./yearly_stats/\"):\n",
    "    os.makedirs(\"./yearly_stats/\")\n",
    "\n",
    "if not os.path.exists(\"./player_gamelogs/\"):\n",
    "    os.makedirs(\"./player_gamelogs/\")\n",
    "\n",
    "# Going back as far as the beginning of Brady's career\n",
    "years = [x for x in range(2015, 2022)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_result(result):\n",
    "    output = re.split(' |-', result['Result'])\n",
    "    output[0] = output[0] == \"W\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "p0nMi4WMPVFs"
   },
   "outputs": [],
   "source": [
    "def add_urls(soup, urls, limit=50):\n",
    "    links = soup.find_all('a')\n",
    "    for link in links[:limit*2]:\n",
    "        if not 'team' in link['href']:\n",
    "            urls.add(link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P528vsjNsdEK"
   },
   "outputs": [],
   "source": [
    "# Initialize set for storing player URLs\n",
    "player_urls = set()\n",
    "\n",
    "for year in years:\n",
    "    for stat in stat_categories:\n",
    "        \n",
    "        # Get webpage contents and begin parsing with bs4\n",
    "        url = f\"{base_url}/years/{year}/{stat}.htm\"\n",
    "        webpage = requests.get(url)\n",
    "        page_soup = BeautifulSoup(webpage.content, 'html.parser')\n",
    "        \n",
    "        # Table's ID is slightly different when \n",
    "        if stat == \"scrimmage\":\n",
    "            table_id = \"receiving_and_rushing\"\n",
    "        else:\n",
    "            table_id = stat\n",
    "        \n",
    "        table_soup = page_soup.find('table', {'id': table_id})\n",
    "        \n",
    "        if stat == \"scrimmage\":\n",
    "            add_urls(table_soup, player_urls, 100)\n",
    "        else:\n",
    "            add_urls(table_soup, player_urls)\n",
    "        \n",
    "        stat_df = pd.read_html(str(table_soup))[0]\n",
    "        \n",
    "        # Clean dataset\n",
    "        if stat != \"passing\":\n",
    "            stat_df.columns = ['_'.join(col).strip('_') if \"level\" not in col[0] else col[1] for col in stat_df.columns.to_flat_index()]\n",
    "            \n",
    "        # Removes duplicate headers throughout table\n",
    "        stat_df = stat_df[stat_df.Rk != \"Rk\"].set_index(\"Rk\")\n",
    "        \n",
    "        # Converts emblemized award recognition to boolean column features\n",
    "        stat_df['ProBowl'] = stat_df.Player.apply(lambda x: '*' in x)\n",
    "        stat_df['AllPro'] = stat_df.Player.apply(lambda x: '+' in x)\n",
    "        stat_df.Player = stat_df.Player.str.strip('*+')\n",
    "        \n",
    "        # Export dataset\n",
    "        stat_df.to_csv(f\"./yearly_stats/{year}_{stat}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The full amount of player gamelogs we have!!!\n",
    "len(player_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laziest way I could import the set back in for comparison\n",
    "completed_logs = set(pd.read_csv(\"./player_urls.csv\").to_numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we're using sets, we can take the inverse of the union of our completed and newly grabbed sets\n",
    "len(player_urls.difference(completed_logs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WuO9hOZHddkE"
   },
   "outputs": [],
   "source": [
    "# We now grab all of the career logs for those we don't already have.\n",
    "new_logs = player_urls.difference(completed_logs)\n",
    "if not new_logs:\n",
    "    print(\"Completed all logs already\")\n",
    "else:\n",
    "    for url in player_urls.difference(completed_logs):\n",
    "\n",
    "        full_url = f\"{base_url}{url[:-4]}/gamelog/\"\n",
    "        webpage = requests.get(full_url)\n",
    "        page_soup = BeautifulSoup(webpage.content, 'html.parser')\n",
    "        table_soup = page_soup.find('table', {'id': 'stats'})\n",
    "        player_name = page_soup.find('h1', {'itemprop': 'name'}).text.strip()\n",
    "\n",
    "        stat_df = pd.read_html(str(table_soup))[0]\n",
    "        stat_df.columns = ['_'.join(col).strip('_') if \"level\" not in col[0] else col[1] for col in stat_df.columns.to_flat_index()]\n",
    "\n",
    "        # Removes duplicate headers throughout table\n",
    "        stat_df = stat_df[stat_df.Rk != \"Rk\"].set_index(\"Rk\")\n",
    "\n",
    "        # Convert Away to bool\n",
    "        stat_df['Away_status'] = np.where(stat_df[\"Unnamed: 7_level_1\"].isnull(), False, True)\n",
    "\n",
    "        # Data Cleaning\n",
    "        stat_df[['Win', 'Score', 'Opp Score']] = stat_df.apply(process_result, result_type='expand', axis=1)\n",
    "        stat_df = stat_df.drop([\"Unnamed: 7_level_1\", \"Result\"], axis=1)\n",
    "        stat_df['GS'] = np.where(stat_df['GS'].isnull(), False, True)\n",
    "        stat_df['Player'] = player_name\n",
    "        \n",
    "        # Export to a new CSV\n",
    "        stat_df.to_csv(f\"./player_gamelogs/{player_name.replace(' ', '_')}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(player_urls.union(completed_logs), columns=['URLs']).to_csv(\"./player_urls.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "NFL_Stats_Scraping.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
