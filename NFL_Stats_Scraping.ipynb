{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MLDS-UT-Austin/FantasyFootball/blob/main/NFL_Stats_Scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "PAXdQ-xzb3VO"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Lh0z5MI-cU0D"
   },
   "outputs": [],
   "source": [
    "base_url = \"https://www.pro-football-reference.com\"\n",
    "stat_categories = [\"passing\", \"scrimmage\", \"kicking\"]\n",
    "\n",
    "if not os.path.exists(\"./yearly_stats/\"):\n",
    "    os.makedirs(\"./yearly_stats/\")\n",
    "\n",
    "if not os.path.exists(\"./player_gamelogs/\"):\n",
    "    os.makedirs(\"./player_gamelogs/\")\n",
    "\n",
    "# Going back as far as the beginning of Brady's career\n",
    "years = [x for x in range(2015, 2022)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "p0nMi4WMPVFs"
   },
   "outputs": [],
   "source": [
    "def add_urls(soup, urls, limit=50):\n",
    "    links = soup.find_all('a')\n",
    "    for link in links[:limit*2]:\n",
    "        if not 'team' in link['href']:\n",
    "            urls.add(link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "P528vsjNsdEK"
   },
   "outputs": [],
   "source": [
    "# Initialize set for storing player URLs\n",
    "player_urls = set()\n",
    "\n",
    "for year in years:\n",
    "    for stat in stat_categories:\n",
    "        \n",
    "        # Get webpage contents and begin parsing with bs4\n",
    "        url = f\"{base_url}/years/{year}/{stat}.htm\"\n",
    "        webpage = requests.get(url)\n",
    "        page_soup = BeautifulSoup(webpage.content, 'html.parser')\n",
    "        \n",
    "        # Table's ID is slightly different when \n",
    "        if stat == \"scrimmage\":\n",
    "            table_id = \"receiving_and_rushing\"\n",
    "        else:\n",
    "            table_id = stat\n",
    "        \n",
    "        table_soup = page_soup.find('table', {'id': table_id})\n",
    "        \n",
    "        if stat == \"scrimmage\":\n",
    "            add_urls(table_soup, player_urls, 100)\n",
    "        else:\n",
    "            add_urls(table_soup, player_urls)\n",
    "        \n",
    "        stat_df = pd.read_html(str(table_soup))[0]\n",
    "        \n",
    "        # Clean dataset\n",
    "        if stat != \"passing\":\n",
    "            stat_df.columns = ['_'.join(col).strip('_') if \"level\" not in col[0] else col[1] for col in stat_df.columns.to_flat_index()]\n",
    "            \n",
    "        # Removes duplicate headers throughout table\n",
    "        stat_df = stat_df[stat_df.Rk != \"Rk\"].set_index(\"Rk\")\n",
    "        \n",
    "        # Converts emblemized award recognition to boolean column features\n",
    "        stat_df['ProBowl'] = stat_df.Player.apply(lambda x: '*' in x)\n",
    "        stat_df['AllPro'] = stat_df.Player.apply(lambda x: '+' in x)\n",
    "        stat_df.Player = stat_df.Player.str.strip('*+')\n",
    "        \n",
    "        # Export dataset\n",
    "        stat_df.to_csv(f\"./yearly_stats/{year}_{stat}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "536"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(player_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "WuO9hOZHddkE"
   },
   "outputs": [],
   "source": [
    "for url in player_urls:\n",
    "    full_url = f\"{base_url}{url[:-4]}/gamelog/\"\n",
    "    webpage = requests.get(full_url)\n",
    "    page_soup = BeautifulSoup(webpage.content, 'html.parser')\n",
    "    table_soup = page_soup.find('table', {'id': 'stats'})\n",
    "    player_name = page_soup.find('h1', {'itemprop': 'name'}).text.strip()\n",
    "    \n",
    "    stat_df = pd.read_html(str(table_soup))[0]\n",
    "    stat_df.columns = ['_'.join(col).strip('_') if \"level\" not in col[0] else col[1] for col in stat_df.columns.to_flat_index()]\n",
    "            \n",
    "    # Removes duplicate headers throughout table\n",
    "    stat_df = stat_df[stat_df.Rk != \"Rk\"].set_index(\"Rk\")\n",
    "    \n",
    "    # Convert Away to bool\n",
    "    stat_df['Away_status'] = np.where(stat_df[\"Unnamed: 7_level_1\"].isnull(), False, True)\n",
    "    stat_df = stat_df.drop([])\n",
    "    stat_df['GS'] = np.where(stat_df['GS'].isnull(), False, True)\n",
    "    stat_df['Player'] = player_name\n",
    "    \n",
    "    stat_df.to_csv(f\"./player_gamelogs/{player_name.replace(' ', '_')}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "NFL_Stats_Scraping.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
